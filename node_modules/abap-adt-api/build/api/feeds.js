"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.dumps = exports.feeds = void 0;
const utilities_1 = require("../utilities");
const parseFeeds = (body) => {
    const raw = (0, utilities_1.fullParse)(body, { removeNSPrefix: true });
    const parseDt = (dt) => {
        const { "@_id": id, label = "" } = dt;
        const operators = (0, utilities_1.xmlArray)(dt, "operators", "operator");
        return { id, label, operators: operators.map((o) => o["@_id"]) };
    };
    const parseAttribute = (at) => {
        var _a;
        const dataType = (_a = at.dataType) === null || _a === void 0 ? void 0 : _a["@_id"];
        return { ...parseDt(at), dataType };
    };
    const parseOperators = (op) => ({ ...(0, utilities_1.xmlNodeAttr)(op), label: op.label });
    const feeds = (0, utilities_1.xmlArray)(raw, "feed", "entry").map((f) => {
        var _a, _b;
        const author = (0, utilities_1.xmlNode)(f, "author", "name");
        const { href, type: accept } = (0, utilities_1.xmlNodeAttr)(f["link"]);
        const { published, summary, title, updated } = f;
        const ed = f.extendedData;
        const refresh = (0, utilities_1.xmlNodeAttr)((_a = ed === null || ed === void 0 ? void 0 : ed.refresh) === null || _a === void 0 ? void 0 : _a.interval);
        const paging = (_b = ed === null || ed === void 0 ? void 0 : ed.paging) === null || _b === void 0 ? void 0 : _b['@_size'];
        const { queryIsObligatory, queryDepth } = ed;
        const operators = (0, utilities_1.xmlArray)(ed, "operators", "operator").map(parseOperators);
        const dataTypes = (0, utilities_1.xmlArray)(ed, "dataTypes", "dataType").map(parseDt);
        const attributes = (0, utilities_1.xmlArray)(ed, "attributes", "attribute").map(parseAttribute);
        const queryVariants = (0, utilities_1.xmlArray)(ed, "queryVariants", "queryVariant").map(utilities_1.xmlNodeAttr);
        return {
            author, href, published: (0, utilities_1.parseJsonDate)(published), summary, title, updated: (0, utilities_1.parseJsonDate)(updated), accept, refresh, paging,
            operators, dataTypes, attributes,
            queryIsObligatory, queryDepth, queryVariants
        };
    });
    return feeds;
};
const parseDumps = (body) => {
    var _a;
    const raw = (_a = (0, utilities_1.fullParse)(body, { removeNSPrefix: true })) === null || _a === void 0 ? void 0 : _a.feed;
    const { href } = (0, utilities_1.xmlNodeAttr)(raw === null || raw === void 0 ? void 0 : raw.link);
    const { title, updated } = raw;
    const dumps = (0, utilities_1.xmlArray)(raw, "entry").map((e) => {
        const { category, id, author: { name: author }, summary: { "#text": text, "@_type": type } } = e;
        const links = (0, utilities_1.xmlArray)(e, "link").map(utilities_1.xmlNodeAttr);
        return { categories: category.map(utilities_1.xmlNodeAttr), links, id, author, text: text, type };
    });
    return { href, title, updated: (0, utilities_1.parseJsonDate)(updated), dumps };
};
async function feeds(h) {
    const headers = { Accept: "application/atom+xml;type=feed" };
    const response = await h.request("/sap/bc/adt/feeds", { method: "GET", headers });
    return parseFeeds(response.body);
}
exports.feeds = feeds;
async function dumps(h, query = "") {
    const headers = { Accept: "application/atom+xml;type=feed" };
    const qs = {};
    if (query)
        qs["$query"] = query;
    const response = await h.request("/sap/bc/adt/runtime/dumps", { method: "GET", qs, headers });
    return parseDumps(response.body);
}
exports.dumps = dumps;
